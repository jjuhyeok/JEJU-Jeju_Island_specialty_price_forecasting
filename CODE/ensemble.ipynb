{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ML_AG_1 = pd.read_csv(\"auto_submission_feature.csv\")\n",
    "ML_AG_2 = pd.read_csv(\"auto_submission_feature2.csv\")\n",
    "ML_AG_4 = pd.read_csv(\"auto_submission_feature4.csv\")\n",
    "ML_AG_6 = pd.read_csv(\"auto_submission_feature6.csv\")\n",
    "ML_AG_7 = pd.read_csv(\"auto_submission_feature7.csv\")\n",
    "ML_AG_8 = pd.read_csv(\"auto_submission.csv\")\n",
    "ML_AG_1.loc[ML_AG_1['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_2.loc[ML_AG_2['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_4.loc[ML_AG_4['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_6.loc[ML_AG_6['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_7.loc[ML_AG_7['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_8.loc[ML_AG_8['answer'] < 0.0, 'answer'] = 0.0\n",
    "\n",
    "ML_AG = ML_AG_1.copy()\n",
    "ML_AG['answer'] = (ML_AG_1['answer'] + ML_AG_2['answer'] + ML_AG_4['answer'] + ML_AG_6['answer'] + ML_AG_7['answer'] + ML_AG_8['answer']) / 6\n",
    "\n",
    "ML_AG_1_v2 = pd.read_csv(\"autogluon_regression_real_final.csv\")\n",
    "ML_AG_2_v2 = pd.read_csv(\"autogluon_regression_final222.csv\")\n",
    "ML_AG_3_v2 = pd.read_csv(\"autogluon_regression_real_final_WeightedEnsemble_L3.csv\")\n",
    "ML_AG_1_v2.loc[ML_AG_1_v2['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_2_v2.loc[ML_AG_2_v2['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_3_v2.loc[ML_AG_3_v2['answer'] < 0.0, 'answer'] = 0.0\n",
    "ML_AG_v2 = ML_AG_1_v2.copy()\n",
    "ML_AG_v2['answer'] = (ML_AG_1_v2['answer'] + ML_AG_2_v2['answer'] + ML_AG_3_v2['answer']) / 3\n",
    "\n",
    "\n",
    "XGB_1 = pd.read_csv(\"xgboost_timeseries.csv\")\n",
    "XGB_2 = pd.read_csv(\"xgboost_timeseries2.csv\")\n",
    "XGB_1.loc[XGB_1['answer'] < 0.0, 'answer'] = 0.0\n",
    "XGB_2.loc[XGB_2['answer'] < 0.0, 'answer'] = 0.0\n",
    "\n",
    "XGB = XGB_1.copy()\n",
    "XGB['answer'] = (XGB_1['answer'] + XGB_2['answer']) / 2\n",
    "\n",
    "mlj_1 = pd.read_csv(\"MJSEVSEVSEV.csv\")\n",
    "mlj_2 = pd.read_csv(\"MLJAR_21011928.csv\")\n",
    "mlj_3 = pd.read_csv(\"MLJAR_19990313_NEW1_REAL.csv\")\n",
    "mlj_1.loc[mlj_1['answer'] < 0.0, 'answer'] = 0.0\n",
    "mlj_2.loc[mlj_2['answer'] < 0.0, 'answer'] = 0.0\n",
    "mlj_3.loc[mlj_3['answer'] < 0.0, 'answer'] = 0.0\n",
    "\n",
    "\n",
    "mlj = mlj_1.copy()\n",
    "mlj['answer'] = (mlj_1['answer'] + mlj_2['answer'] + mlj_3['answer']) / 3\n",
    "\n",
    "\n",
    "DL_1 = pd.read_csv(\"TG_TOALL_RE1.csv\")\n",
    "DL_2 = pd.read_csv(\"TG_TOALL_RE1_seed.csv\") \n",
    "DL_1.loc[DL_1['answer'] < 0.0, 'answer'] = 0.0\n",
    "DL_2.loc[DL_2['answer'] < 0.0, 'answer'] = 0.0\n",
    "\n",
    "DL = DL_1.copy()\n",
    "DL['answer'] = (DL_1['answer']*0.2) + (DL_2['answer']*0.8)\n",
    "\n",
    "\n",
    "Final = DL_1.copy()\n",
    "\n",
    "\n",
    "Final['date'] = Final['ID'].str.extract(r'_(\\d{8})$')[0]\n",
    "Final['date'] = pd.to_datetime(Final['date'], format='%Y%m%d')\n",
    "date_threshold = pd.Timestamp('2023-03-19')\n",
    "before_threshold = Final['date'] <= date_threshold\n",
    "after_threshold = Final['date'] > date_threshold\n",
    "Final['item'] = Final['ID'].str.extract(r'^([A-Za-z]+)_')[0]\n",
    "is_TG = Final['item'] == 'TG'\n",
    "not_TG = ~is_TG\n",
    "Final.loc[before_threshold, 'answer'] = (\n",
    "    DL.loc[before_threshold, 'answer'] * 0.6 +\n",
    "    ML_AG.loc[before_threshold, 'answer'] * 0.1 +\n",
    "    ML_AG_v2.loc[before_threshold, 'answer'] * 0.1 +\n",
    "    XGB.loc[before_threshold, 'answer'] * 0.1 +\n",
    "    mlj.loc[before_threshold, 'answer'] * 0.1\n",
    ")\n",
    "Final.loc[after_threshold & is_TG, 'answer'] = (\n",
    "    XGB.loc[after_threshold & is_TG, 'answer'] * 0.3 +\n",
    "    mlj.loc[after_threshold & is_TG, 'answer'] * 0.4 + \n",
    "    ML_AG_v2.loc[after_threshold, 'answer'] * 0.3\n",
    ")\n",
    "Final.loc[after_threshold & not_TG, 'answer'] = (\n",
    "    DL.loc[after_threshold, 'answer'] * 0.6 +\n",
    "    ML_AG.loc[after_threshold, 'answer'] * 0.1 +\n",
    "    ML_AG_v2.loc[after_threshold, 'answer'] * 0.1 +\n",
    "    XGB.loc[after_threshold, 'answer'] * 0.1 +\n",
    "    mlj.loc[after_threshold, 'answer'] * 0.1\n",
    ")\n",
    "\n",
    "Final.drop(columns=['date'], inplace=True)\n",
    "\n",
    "Final['itemcorloc'] = Final[\"ID\"].str[:6]\n",
    "Final[\"answer\"][Final[\"itemcorloc\"] == \"RD_E_S\"] = Final[\"answer\"][Final[\"itemcorloc\"] == \"RD_E_S\"]*2\n",
    "Final[\"answer\"][Final[\"itemcorloc\"] == \"RD_E_S\"]\n",
    "Final.drop(['itemcorloc'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "dates_to_update = pd.date_range(start='2023-03-04', end='2023-03-12').strftime('%Y-%m-%d').tolist()\n",
    "filtered_data = train[(train['timestamp'].isin(['2023-03-01', '2023-03-02', '2023-03-03'])) & (train['supply(kg)'] == 0)]\n",
    "grouped_data = filtered_data.groupby(['item', 'corporation', 'location']).size().reset_index(name='count')\n",
    "combinations_with_zero_supply = grouped_data[grouped_data['count'] == 3]\n",
    "for index, row in combinations_with_zero_supply.iterrows():\n",
    "    item, corporation, location = row['item'], row['corporation'], row['location']\n",
    "    for date in dates_to_update:\n",
    "        formatted_date = date.replace('-', '')\n",
    "        id_value = f\"{item}_{corporation}_{location}_{formatted_date}\"\n",
    "        Final.loc[Final['ID'] == id_value, 'answer'] = 0\n",
    "dates_to_filter = pd.date_range(start='2023-02-21', end='2023-03-03').strftime('%Y-%m-%d').tolist()\n",
    "dates_to_update = pd.date_range(start='2023-03-04', end='2023-03-31').strftime('%Y-%m-%d').tolist()\n",
    "filtered_data = train[(train['timestamp'].isin(dates_to_filter)) & (train['supply(kg)'] == 0)]\n",
    "grouped_data = filtered_data.groupby(['item', 'corporation', 'location']).size().reset_index(name='count')\n",
    "days_in_filter_range = len(dates_to_filter)\n",
    "combinations_with_zero_supply = grouped_data[(grouped_data['count'] == days_in_filter_range) & ((grouped_data['item'] == 'BC') | (grouped_data['item'] == 'RD') | (grouped_data['item'] == 'CR'))]\n",
    "\n",
    "final_data = Final.copy()\n",
    "for index, row in combinations_with_zero_supply.iterrows():\n",
    "    item, corporation, location = row['item'], row['corporation'], row['location']\n",
    "    for date in dates_to_update:\n",
    "        formatted_date = date.replace('-', '')\n",
    "        id_value = f\"{item}_{corporation}_{location}_{formatted_date}\"\n",
    "        final_data.loc[final_data['ID'] == id_value, 'answer'] = 0\n",
    "\n",
    "Final = final_data.copy()\n",
    "sunday_ids_march_2023 = [f\"_202303{day:02}\" for day in [5, 12, 19, 26]]\n",
    "for sunday_id in sunday_ids_march_2023:\n",
    "    Final.loc[Final['ID'].str.contains(sunday_id), 'answer'] = 0\n",
    "Final.drop(['item'],axis=1,inplace=True)\n",
    "Final.to_csv('FINAL_2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
